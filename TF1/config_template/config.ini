[dirs]
# Stores summaries and final model checkpoints (should be backed up).
log = ../log
# Stores intermediate checkpoints (does not need to be be backed up)
checkpoints = ../log/checkpoints
# Stores training and evaluation data (should be able to hold > 100GB).
data = ../data

# Comment out to copy the files to a temporary dir before starting training
# Files are cleaned up automatically after finishing training and evaluation
#fast = /fastdata/smeister/data

[compile]
# g++-4.x binary to use for op compilation
g++ = g++

[run]
# If true, only a minimum subset of the large training datasets will be downloaded.
# Set to true for machines on which you don't need to run the full training.
development = False

# Number of threads for loading input examples
num_input_threads = 1

# Total batch size, must be divisible by the number of GPUs.
batch_size = 4

# GPU device IDs to train on, comma separated (multi-GPU training supported!)
# Note: checkpoint evaluation during training will use the default device
# (generally the first GPU)
gpu_list = 0

# Enable to show a live visualization of the latest checkpoint evaluation
# while training
# interactive_plot = True

# Dataset to *train* on.
# One of {synthia, kitti, kitti_ft, cityscapes, chairs}.
dataset = synthia

[train]

# Interval for halving the learning rate
decay_interval = 100000

# Interval for saving checkpoints.
# After each save, training is interrupted, the checkpoint is evaluated,
# and training is continued from that checkpoint.
save_interval = 5000

# Interval for displaying and saving training logs
display_interval = 50

# Specify architecture using the naming convention from our paper
# (borrowed from FlowNet 2.0, https://arxiv.org/abs/1612.01925).
# E.g. C to train UnFlow-C, CS to train UnFlow-CSS, CSS to train UnFlow-CSS.
# Use small letters to use smaller networks, as in FlowNet 2.0.
flownet = C

# If unspecified, only the final network is trained and any previous networks are kept fixed.
# Currently, end-to-end training is only supported for SUPERVISED training,
# i.e., uncomment this when run['dataset'] = kitti_ft.
#train_all = true

# Names of experiments to use for initializing the network(s).
# Comma separated, one name for each network to initialize from a different experiment.
# E.g., when training UnFlowCSS, use UnFlowC,UnFlowCS to use the UnFlowC experiment for
# first network and UnFlowCS for the second network.
#finetune = S

# Use two additional upconv layers to expand to full resolution in final network.
# If false/unset, uses bilinear upsampling (x4).
# DO NOT UNCOMMENT - THIS DOES CURRENTLY NOT YIELD GOOD RESULTS
#full_res = True

# Compute a loss at each stage when training in an unsupervised way,
# i.e. when dataset is not kitti_ft.
# JUST LEAVE IT SET TO TRUE ALWAYS TO REPLICATE OUR RESULTS
pyramid_loss = True

# -----------------------------------------------------------------------------
# Masking & occlusion handling

# Occlusion detection mode to use 'disocc' to use reverse disocc, 'fb' to use fb check.
# In the paper, we only use fb (disocc is still broken).
#mask_occlusion = fb

# Constant penalty for occluded pixels to avoid all pixels becoming "occluded".
# Uncomment whenever the mask_occlusion flag is used
#occ_weight = 12.4

# Penalize pixels where occlusion does not match disocclusion of reverse flow.
# DISOCCLUSION IS CURRENTLY BROKEN - DON'T USE THIS
#sym_weight = 15.6

# Mask border regions in data term
# JUST LEAVE THIS SET TO TRUE
border_mask = True

# -----------------------------------------------------------------------------
# Data term (multiple terms may be combined)

# Encourages forward and backward flow to be opposite to each other (if not masked)
#fb_weight = 0.2

# Gradient error between backward warped second image and first image.
# NOT TESTED YET - USE ON YOUR OWN RISK
#grad_weight = 1.0

# Color error between backward warped second image and first image.
#photo_weight = 1.0

# Ternary transform error between backward warped second image and first image.
ternary_weight = 1.0

# -----------------------------------------------------------------------------
# Regularization (ONLY ONE LINE OF THESE SHOULD BE UNCOMMENTED)

# Use first order smoothness
#smooth_1st_weight = 3.0

# Use second order smoothness
smooth_2nd_weight = 3.0


# -----------------------------------------------------------------------------
# SETTINGS IN THE train_{} CATEGORIES (BELOW, e.g. train_kitti) OVERWRITE GLOBAL
# TRAINING SETTINGS. One category for each training dataset.
# -----------------------------------------------------------------------------
# For each dataset, height, width, num_iters, learning_rate and decay_after are
# required. All other parameters are read from the global section if not specified.

[train_chairs]
# Image dimensions to randomly crop to.
# Ensure that all images in the corresponding dataset are at least that large.
height = 384
width = 512

# Total number of iterations.
num_iters = 600000

# Initial learning rate.
# Divided by two every <decay_interval> iterations.
# Counting starts after decay_after iterations.
learning_rate = 1.0e-4

# Decay after this many iterations
decay_after = 200000

[train_kitti_ft]
height = 320
width = 768

# Fine grained learning schedule for fine-tuning.
# Both lists must have the same number of comma separated elements
manual_decay_iters = 45000,20000,20000,10000,2500,2500
manual_decay_lrs = 0.5e-5,0.25e-5,0.1e-5,0.05e-5,0.25e-6,0.1e-6

[train_synthia]
height = 512
width = 768
num_iters = 500000
learning_rate =  1.0e-4
decay_after = 100000

[train_kitti]
height = 320
width = 1152
num_iters = 500000
learning_rate = 1.0e-5
decay_after = 100000
fb_weight = 0.2
mask_occlusion = fb
occ_weight = 12.4

[train_cityscapes]
height = 512
width = 1024
num_iters = 500000
learning_rate = 1.0e-5
decay_after = 100000
fb_weight = 0.2
mask_occlusion = fb
occ_weight = 12.4
